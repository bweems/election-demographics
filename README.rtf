{\rtf1\ansi\ansicpg1252\cocoartf1187\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 README.txt\
\
File: classifier.py\
	This file runs our classifier.  \
\
multithreaded_feature_finder(): creates threads for each issue, which contains the tag, baseline_error, and all available features.  The baseline error is pre-calculated by getting the testing error on "HC02_EST_VC02" with 100 iterations.  The threads are then run in parallel, and when all have finished the important data is printed.  Each thread selects the features for its tag.\
	The best features are found by finding the 10 best individual features.  This is done by getting the testing error of the feature over a constant number of iterations.  This testing error is compared to the baseline, and if the testing error is below the baseline the feature is retained in the feature list.  This is run recursively, with the testing error averaged over all runs.  Once the feature list contains 10 or fewer features the remaining features are returned.  The testing_error with these features is measured and compared to the baseline error.\
	The testing error is found as an average of NUM_ITERS individual runs.  Each run runs the function test_features.  This splits the issues classified by the specified tag into a training set containing 3/4 of the propositions and a testing set containing 1/4 of them.  We then use the training issues to build a classifier model using an SVM with an rbf kernel.  We use the testing set to test our model by comparing our prediction to the actual results of each county and taking the number of errors/number of test cases.}